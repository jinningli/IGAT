{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(df):\n",
    "    \"\"\"\n",
    "    Splits the label field by '-' (stance-topic) from df into two columns: pred_stance, pred_topic.\n",
    "    For example, \"pro-USA\" => pred_stance: \"pro\", pred_topic: \"USA\"\n",
    "    \"\"\"\n",
    "    if \"pred_label\" not in df.columns:\n",
    "        raise KeyError(\"DataFrame does not contain a 'label' column.\")\n",
    "\n",
    "    # Split \"label\" into two columns: pred_stance, pred_topic\n",
    "    df[[\"pred_stance\", \"pred_topic\"]] = df[\"pred_label\"].str.split(\"-\", n=1, expand=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load RoBERTa in eval mode\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embedding(tweet):\n",
    "    \"\"\"\n",
    "    Return the CLS embedding from the last hidden state of RoBERTa\n",
    "    \"\"\"\n",
    "    encoded_input = tokenizer(tweet, \n",
    "                              return_tensors='pt', \n",
    "                              truncation=True, \n",
    "                              max_length=512)\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input, output_hidden_states=True)\n",
    "        last_layer_hidden_states = output.hidden_states[-1]  # shape: (batch, seq_len, hidden_dim)\n",
    "        cls_embedding = last_layer_hidden_states[:, 0, :]    # shape: (batch, hidden_dim)\n",
    "    return cls_embedding.cpu().numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/path1/path2/ssbrl/data/learning-to-slice/US_election_dataset.csv\"\n",
    "output_path = \"labeled_data/labelled.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df = df.drop_duplicates(subset=\"text\", keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "# Subset of labeled rows for discovering the best mapping\n",
    "df_labeled = df[df[\"is_gt\"] == 1].copy()\n",
    "if len(df_labeled) == 0:\n",
    "    raise ValueError(\"No labeled rows found (is_gt==1). Cannot find best mapping!\")\n",
    "\n",
    "df_labeled = df_labeled[df_labeled[\"manual_label\"] != \"neutral\"]\n",
    "\n",
    "# We assume df_labeled[\"manual_label_full\"] has exactly 4 possible classes\n",
    "unique_labels = df_labeled[\"manual_label_full\"].unique()\n",
    "unique_labels = sorted(unique_labels)  # ensure consistent order\n",
    "if len(unique_labels) != 4:\n",
    "    print(\"Warning: found these ground-truth labels in the labeled set:\", unique_labels)\n",
    "    print(\"But we are expecting exactly 4 distinct classes. Proceeding anyway...\")\n",
    "\n",
    "# Map label string -> integer index (0..3)\n",
    "label2idx = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "idx2label = {v: k for k, v in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'opposing-Candidate_Advocacy': 0, 'opposing-Election_Legitimacy': 1, 'supportive-Candidate_Advocacy': 2, 'supportive-Election_Legitimacy': 3}\n",
      "{0: 'opposing-Candidate_Advocacy', 1: 'opposing-Election_Legitimacy', 2: 'supportive-Candidate_Advocacy', 3: 'supportive-Election_Legitimacy'}\n"
     ]
    }
   ],
   "source": [
    "# Inspections:\n",
    "print(label2idx)\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding all 4275 tweets...\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Embed ALL TWEETS\n",
    "# --------------------------\n",
    "print(f\"Embedding all {len(df)} tweets...\")\n",
    "start_time = time.time()\n",
    "embeddings = []\n",
    "for text in df[\"text\"]:\n",
    "    emb = get_cls_embedding(text)\n",
    "    embeddings.append(emb)\n",
    "embeddings_array = np.vstack(embeddings)  # shape: (N, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KMeans(n_clusters=4)...\n",
      "Done embedding. Time: 41.50s\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# KMeans (4 clusters)\n",
    "# --------------------------\n",
    "print(\"Running KMeans(n_clusters=4)...\")\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings_array)\n",
    "end_time = time.time()\n",
    "print(f\"Done embedding. Time: {end_time - start_time:.2f}s\")\n",
    "cluster_ids = kmeans.labels_  # cluster assignments for each row in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store cluster in df\n",
    "df[\"cluster_id\"] = cluster_ids\n",
    "np.unique(cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perm: (0, 1, 2, 3)\n",
      "----acc: 0.2098092643051771\n",
      "perm: (0, 1, 3, 2)\n",
      "----acc: 0.36239782016348776\n",
      "perm: (0, 2, 1, 3)\n",
      "----acc: 0.29155313351498635\n",
      "perm: (0, 2, 3, 1)\n",
      "----acc: 0.3569482288828338\n",
      "perm: (0, 3, 1, 2)\n",
      "----acc: 0.335149863760218\n",
      "perm: (0, 3, 2, 1)\n",
      "----acc: 0.24795640326975477\n",
      "perm: (1, 0, 2, 3)\n",
      "----acc: 0.12806539509536785\n",
      "perm: (1, 0, 3, 2)\n",
      "----acc: 0.28065395095367845\n",
      "perm: (1, 2, 0, 3)\n",
      "----acc: 0.22888283378746593\n",
      "perm: (1, 2, 3, 0)\n",
      "----acc: 0.2779291553133515\n",
      "perm: (1, 3, 0, 2)\n",
      "----acc: 0.2724795640326976\n",
      "perm: (1, 3, 2, 0)\n",
      "----acc: 0.16893732970027248\n",
      "perm: (2, 0, 1, 3)\n",
      "----acc: 0.1907356948228883\n",
      "perm: (2, 0, 3, 1)\n",
      "----acc: 0.2561307901907357\n",
      "perm: (2, 1, 0, 3)\n",
      "----acc: 0.2098092643051771\n",
      "perm: (2, 1, 3, 0)\n",
      "----acc: 0.25885558583106266\n",
      "perm: (2, 3, 0, 1)\n",
      "----acc: 0.24795640326975477\n",
      "perm: (2, 3, 1, 0)\n",
      "----acc: 0.23160762942779292\n",
      "perm: (3, 0, 1, 2)\n",
      "----acc: 0.26430517711171664\n",
      "perm: (3, 0, 2, 1)\n",
      "----acc: 0.1771117166212534\n",
      "perm: (3, 1, 0, 2)\n",
      "----acc: 0.28337874659400547\n",
      "perm: (3, 1, 2, 0)\n",
      "----acc: 0.17983651226158037\n",
      "perm: (3, 2, 0, 1)\n",
      "----acc: 0.2779291553133515\n",
      "perm: (3, 2, 1, 0)\n",
      "----acc: 0.2615803814713896\n",
      "Best accuracy among labeled data = 0.3624\n",
      "Best cluster->label mapping: {0: 0, 1: 1, 2: 3, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "#  Find best permutation using ONLY the labeled subset\n",
    "# --------------------------\n",
    "# (1) We'll extract the cluster assignments for the labeled portion\n",
    "labeled_indices = df_labeled.index  # row indices in df\n",
    "labeled_clusters = df.loc[labeled_indices, \"cluster_id\"].values\n",
    "\n",
    "# (2) Convert ground-truth label -> label_idx\n",
    "df_labeled[\"label_idx\"] = df_labeled[\"manual_label_full\"].map(label2idx)\n",
    "labeled_gt = df_labeled[\"label_idx\"].values  # ground truth array (0..3)\n",
    "\n",
    "best_accuracy = -1.0\n",
    "best_mapping = {}\n",
    "\n",
    "# Permutations of [0,1,2,3]\n",
    "for perm in permutations(range(4)):\n",
    "    # clusterID -> label_idx\n",
    "    cluster2label = {cid: perm[cid] for cid in range(4)}\n",
    "\n",
    "    # Predicted label for the labeled portion\n",
    "    pred_label_idx = [cluster2label[c] for c in labeled_clusters]\n",
    "    \n",
    "    # Compute accuracy among labeled data\n",
    "    correct = sum(\n",
    "        1 for gt, pred in zip(labeled_gt, pred_label_idx) if gt == pred\n",
    "    )\n",
    "    accuracy = correct / len(labeled_gt)\n",
    "    print(f\"perm: {perm}\")\n",
    "    print(f\"----acc: {accuracy}\")\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_mapping = cluster2label\n",
    "\n",
    "print(f\"Best accuracy among labeled data = {best_accuracy:.4f}\")\n",
    "print(f\"Best cluster->label mapping: {best_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on labeled data = 0.3624\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "#  Final predictions for ALL data\n",
    "# --------------------------\n",
    "final_pred_idx = [best_mapping[c] for c in df[\"cluster_id\"]]\n",
    "pred_labels_str = [idx2label[i] for i in final_pred_idx]\n",
    "df[\"pred_label\"] = pred_labels_str\n",
    "df = split_label(df)\n",
    "\n",
    "# (Optional) measure final accuracy on the labeled subset (should match best_accuracy)\n",
    "labeled_pred_idx = [best_mapping[c] for c in labeled_clusters]\n",
    "correct_final = sum(1 for gt, pred in zip(labeled_gt, labeled_pred_idx) if gt == pred)\n",
    "final_accuracy = correct_final / len(labeled_gt)\n",
    "print(f\"Final accuracy on labeled data = {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final results (including pred_label) to labeled_data/labelled.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "#  Save results\n",
    "# --------------------------\n",
    "if output_path is not None:\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved final results (including pred_label) to {output_path}\")\n",
    "else:\n",
    "    print(\"No output_path given. Not saving CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
